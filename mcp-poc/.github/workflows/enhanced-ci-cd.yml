name: Enhanced CI/CD Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]
  workflow_dispatch:
    inputs:
      deploy_to_kind:
        description: 'Deploy to kind cluster'
        required: false
        default: 'true'
        type: boolean

env:
  REGISTRY: ghcr.io
  PYTHON_VERSION: "3.11"
  GO_VERSION: "1.21"
  NODE_VERSION: "18"
  COSIGN_EXPERIMENTAL: 1

jobs:
  # Matrix strategy for multi-service builds
  prepare:
    name: Prepare Build Matrix
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
    steps:
    - name: Checkout
      uses: actions/checkout@v4
      
    - name: Set up build matrix
      id: set-matrix
      run: |
        # Define services and their configurations
        cat > matrix.json << EOF
        {
          "include": [
            {
              "service": "text-summarization",
              "path": "services/text-summarization",
              "dockerfile": "services/text-summarization/Dockerfile",
              "language": "python",
              "test_cmd": "make test",
              "security_cmd": "make security-scan"
            },
            {
              "service": "context-service", 
              "path": "services/context-service",
              "dockerfile": "services/context-service/Dockerfile",
              "language": "python",
              "test_cmd": "python -m pytest tests/ -v",
              "security_cmd": "bandit -r . && safety check"
            },
            {
              "service": "auth-service",
              "path": "services/text-summarization/auth-service", 
              "dockerfile": "services/text-summarization/auth-service/Dockerfile",
              "language": "go",
              "test_cmd": "make test",
              "security_cmd": "govulncheck ./..."
            }
          ]
        }
        EOF
        echo "matrix=$(cat matrix.json | jq -c .)" >> $GITHUB_OUTPUT

  # Unit and Security Tests
  test:
    name: Test & Security Scan
    runs-on: ubuntu-latest
    needs: prepare
    strategy:
      matrix: ${{fromJson(needs.prepare.outputs.matrix)}}
      fail-fast: false
    
    services:
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_USER: test_user
          POSTGRES_PASSWORD: test_password
          POSTGRES_DB: test_mcp_db
        ports:
          - 5432:5432
        options: >-
          --health-cmd="pg_isready -U test_user -d test_mcp_db"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=5

    steps:
    - name: Checkout
      uses: actions/checkout@v4

    - name: Set up Python
      if: matrix.language == 'python'
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Create virtual environment
      if: matrix.language == 'python'
      run: |
        python -m venv venv
        echo "${{ github.workspace }}/venv/bin" >> $GITHUB_PATH

    - name: Set up Go
      if: matrix.language == 'go'
      uses: actions/setup-go@v4
      with:
        go-version: ${{ env.GO_VERSION }}

    - name: Cache pip dependencies
      if: matrix.language == 'python'
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles(format('{0}/requirements.lock', matrix.path), format('{0}/requirements.txt', matrix.path)) }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Cache Go modules
      if: matrix.language == 'go'
      uses: actions/cache@v3
      with:
        path: ~/go/pkg/mod
        key: ${{ runner.os }}-go-${{ hashFiles(format('{0}/go.sum', matrix.path)) }}
        restore-keys: |
          ${{ runner.os }}-go-

    - name: Install Python dependencies
      if: matrix.language == 'python'
      working-directory: ${{ matrix.path }}
      run: |
        python -m pip install --upgrade pip
        # Install from locked requirements for reproducible builds
        if [ -f requirements.lock ]; then
          pip install -r requirements.lock
        else
          pip install -r requirements.txt
        fi
        # Install additional dev tools if not in lock file
        pip install pytest pytest-cov bandit safety

    - name: Install Go dependencies
      if: matrix.language == 'go'
      working-directory: ${{ matrix.path }}
      run: |
        go mod download
        go install golang.org/x/vuln/cmd/govulncheck@latest

    - name: Run unit tests with coverage
      working-directory: ${{ matrix.path }}
      env:
        DB_HOST: localhost
        DB_PORT: 5432
        DB_NAME: test_mcp_db
        DB_USER: test_user
        DB_PASSWORD: test_password
      run: |
        if [ "${{ matrix.language }}" = "python" ]; then
          # Run Python tests with coverage
          python -m pytest tests/ -v --cov=. --cov-report=xml --cov-report=html --junitxml=test-results.xml
        else
          # Run Go tests with coverage
          go test -v -cover -coverprofile=coverage.out ./...
          go tool cover -html=coverage.out -o coverage.html
        fi

    - name: Run security scans
      working-directory: ${{ matrix.path }}
      run: |
        echo "Running security scans for ${{ matrix.service }}..."
        if [ "${{ matrix.language }}" = "python" ]; then
          # Python security scans
          bandit -r . -f json -o bandit-report.json || true
          safety check --json --output safety-report.json || true
          # Convert to SARIF if possible
          bandit -r . -f sarif -o bandit-results.sarif || true
        else
          # Go security scans
          govulncheck -json ./... | tee govulncheck-report.json || true
        fi
      continue-on-error: true

    - name: Upload test results and coverage
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: test-results-${{ matrix.service }}
        path: |
          ${{ matrix.path }}/test-results.xml
          ${{ matrix.path }}/coverage.xml
          ${{ matrix.path }}/coverage.html
          ${{ matrix.path }}/coverage.out
          ${{ matrix.path }}/bandit-results.sarif
          ${{ matrix.path }}/bandit-report.json
          ${{ matrix.path }}/safety-report.json
          ${{ matrix.path }}/govulncheck-report.json
        retention-days: 30

    - name: Upload SARIF security results
      uses: github/codeql-action/upload-sarif@v2
      if: always() && matrix.language == 'python'
      with:
        sarif_file: ${{ matrix.path }}/bandit-results.sarif
        category: security-${{ matrix.service }}
      continue-on-error: true

  # Integration Tests
  integration-test:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: test
    
    services:
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_USER: test_user
          POSTGRES_PASSWORD: test_password
          POSTGRES_DB: test_mcp_db
        ports:
          - 5432:5432
        options: >-
          --health-cmd="pg_isready -U test_user -d test_mcp_db"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=5

    steps:
    - name: Checkout
      uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Create virtual environment
      run: |
        python -m venv venv
        echo "${{ github.workspace }}/venv/bin" >> $GITHUB_PATH

    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-integration-${{ hashFiles('tests/requirements.lock', 'tests/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-integration-
          ${{ runner.os }}-pip-

    - name: Install test dependencies
      working-directory: ./tests
      run: |
        python -m pip install --upgrade pip
        # Install from locked requirements for reproducible builds
        if [ -f requirements.lock ]; then
          pip install -r requirements.lock
        else
          pip install -r requirements.txt
        fi
        # Install additional test tools
        pip install pytest-cov pytest-xdist pytest-html

    - name: Run integration tests
      env:
        DB_HOST: localhost
        DB_PORT: 5432
        DB_NAME: test_mcp_db
        DB_USER: test_user
        DB_PASSWORD: test_password
      run: |
        pytest tests/ --tb=short --disable-warnings --maxfail=1 --cov=. --cov-report=xml --cov-report=html --html=integration-report.html

    - name: Upload integration test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: integration-test-results
        path: |
          tests/coverage.xml
          tests/coverage.html
          tests/integration-report.html
        retention-days: 30

  # End-to-End Tests
  e2e-tests:
    name: E2E Tests
    runs-on: ubuntu-latest
    needs: integration-test
    
    services:
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_USER: test_user
          POSTGRES_PASSWORD: test_password
          POSTGRES_DB: test_mcp_db
        ports:
          - 5432:5432
        options: >-
          --health-cmd="pg_isready -U test_user -d test_mcp_db"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=5

    steps:
    - name: Checkout
      uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Create virtual environment
      run: |
        python -m venv venv
        echo "${{ github.workspace }}/venv/bin" >> $GITHUB_PATH

    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-e2e-${{ hashFiles('tests/e2e/requirements.txt', 'tests/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-e2e-
          ${{ runner.os }}-pip-

    - name: Install e2e test dependencies
      run: |
        python -m pip install --upgrade pip
        # Install root test dependencies
        if [ -f tests/requirements.lock ]; then
          pip install -r tests/requirements.lock
        else
          pip install -r tests/requirements.txt
        fi
        # Install e2e specific dependencies if they exist
        if [ -f tests/e2e/requirements.txt ]; then
          pip install -r tests/e2e/requirements.txt
        fi
        # Install additional e2e tools
        pip install pytest-cov pytest-html pytest-timeout

    - name: Run E2E workflow tests
      env:
        DB_HOST: localhost
        DB_PORT: 5432
        DB_NAME: test_mcp_db
        DB_USER: test_user
        DB_PASSWORD: test_password
      run: |
        echo "Running end-to-end workflow tests..."
        python tests/e2e/test_workflow.py
        
        # Run pytest-based e2e tests if they exist
        if [ -d "tests/e2e" ] && [ -n "$(find tests/e2e -name 'test_*.py' -o -name '*_test.py')" ]; then
          pytest tests/e2e/ -v --timeout=300 --cov=. --cov-report=xml --cov-report=html --html=e2e-report.html
        fi

    - name: Upload E2E test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: e2e-test-results
        path: |
          coverage.xml
          coverage.html
          e2e-report.html
        retention-days: 30

  # Build with BuildKit and SBOM generation
  build:
    name: Build & SBOM
    runs-on: ubuntu-latest
    needs: [test, integration-test]
    strategy:
      matrix: ${{fromJson(needs.prepare.outputs.matrix)}}
      fail-fast: false
    
    steps:
    - name: Checkout
      uses: actions/checkout@v4

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
      with:
        driver: docker-container
        use: true

    - name: Log in to Container Registry
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}

    - name: Extract metadata
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.REGISTRY }}/${{ github.repository }}/${{ matrix.service }}
        tags: |
          type=ref,event=branch
          type=ref,event=pr
          type=sha,prefix={{branch}}-
          type=raw,value=latest,enable={{is_default_branch}}

    - name: Install syft for SBOM generation
      run: |
        curl -sSfL https://raw.githubusercontent.com/anchore/syft/main/install.sh | sh -s -- -b /usr/local/bin

    - name: Build and push Docker image with BuildKit
      uses: docker/build-push-action@v5
      id: build
      with:
        context: .
        file: ${{ matrix.dockerfile }}
        platforms: linux/amd64,linux/arm64
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        provenance: true
        sbom: true
        cache-from: type=gha
        cache-to: type=gha,mode=max
        build-args: |
          BUILD_DATE=${{ fromJSON(steps.meta.outputs.json).labels['org.opencontainers.image.created'] }}
          VERSION=${{ fromJSON(steps.meta.outputs.json).labels['org.opencontainers.image.version'] }}
          VCS_REF=${{ github.sha }}

    - name: Generate additional SBOM with syft
      run: |
        # Generate SBOM for the built image
        syft ${{ env.REGISTRY }}/${{ github.repository }}/${{ matrix.service }}:${{ github.sha }} \
          -o spdx-json=sbom-${{ matrix.service }}.spdx.json
        syft ${{ env.REGISTRY }}/${{ github.repository }}/${{ matrix.service }}:${{ github.sha }} \
          -o cyclonedx-json=sbom-${{ matrix.service }}.cyclonedx.json

    - name: Upload SBOM
      uses: actions/upload-artifact@v4
      with:
        name: sbom-${{ matrix.service }}
        path: |
          sbom-${{ matrix.service }}.spdx.json
          sbom-${{ matrix.service }}.cyclonedx.json
        retention-days: 90

    - name: Scan image with Trivy
      uses: aquasecurity/trivy-action@master
      with:
        image-ref: ${{ env.REGISTRY }}/${{ github.repository }}/${{ matrix.service }}:${{ github.sha }}
        format: 'sarif'
        output: 'trivy-${{ matrix.service }}.sarif'

    - name: Upload Trivy scan results
      uses: github/codeql-action/upload-sarif@v2
      if: always()
      with:
        sarif_file: 'trivy-${{ matrix.service }}.sarif'

  # Sign images with Cosign
  sign:
    name: Sign Images
    runs-on: ubuntu-latest
    needs: build
    if: github.ref == 'refs/heads/main'
    strategy:
      matrix: ${{fromJson(needs.prepare.outputs.matrix)}}

    permissions:
      contents: read
      id-token: write

    steps:
    - name: Install Cosign
      uses: sigstore/cosign-installer@v3

    - name: Log in to Container Registry
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}

    - name: Sign container image
      run: |
        cosign sign --yes \
          ${{ env.REGISTRY }}/${{ github.repository }}/${{ matrix.service }}:${{ github.sha }}

    - name: Sign SBOM
      run: |
        # Download SBOM artifact
        echo "Signing SBOM would happen here with actual artifact"
        # In real scenario, you'd download the SBOM and sign it
        # cosign sign-blob --yes sbom-${{ matrix.service }}.spdx.json

  # Deploy to kind cluster for smoke tests
  deploy-kind:
    name: Deploy to Kind
    runs-on: ubuntu-latest
    needs: [build, sign]
    if: github.ref == 'refs/heads/main' || github.event.inputs.deploy_to_kind == 'true'

    steps:
    - name: Checkout
      uses: actions/checkout@v4

    - name: Set up kind
      uses: helm/kind-action@v1.8.0
      with:
        cluster_name: mcp-test
        config: |
          kind: Cluster
          apiVersion: kind.x-k8s.io/v1alpha4
          nodes:
          - role: control-plane
            image: kindest/node:v1.28.0
            kubeadmConfigPatches:
            - |
              kind: InitConfiguration
              nodeRegistration:
                kubeletExtraArgs:
                  node-labels: "ingress-ready=true"
            extraPortMappings:
            - containerPort: 80
              hostPort: 80
              protocol: TCP
            - containerPort: 443
              hostPort: 443
              protocol: TCP

    - name: Set up kubectl
      uses: azure/setup-kubectl@v3

    - name: Install Helm
      uses: azure/setup-helm@v3

    - name: Load images to kind
      run: |
        # Load our built images into kind cluster
        for service in text-summarization context-service auth-service; do
          docker pull ${{ env.REGISTRY }}/${{ github.repository }}/${service}:${{ github.sha }}
          kind load docker-image ${{ env.REGISTRY }}/${{ github.repository }}/${service}:${{ github.sha }} --name mcp-test
        done

    - name: Install PostgreSQL
      run: |
        helm repo add bitnami https://charts.bitnami.com/bitnami
        helm repo update
        helm install postgres bitnami/postgresql \
          --set auth.username=test_user \
          --set auth.password=test_password \
          --set auth.database=test_mcp_db \
          --wait

    - name: Create migration ConfigMaps
      run: |
        echo "Creating ConfigMaps for migrations..."
        
        # Create ConfigMap for main migrations if they exist
        if [ -d "migrations" ]; then
          kubectl create configmap main-migrations --from-file=migrations/ --dry-run=client -o yaml | kubectl apply -f - || true
        fi
        
        # Create ConfigMap for context-service migrations if they exist
        if [ -d "services/context-service/migrations" ]; then
          kubectl create configmap context-migrations --from-file=services/context-service/migrations/ --dry-run=client -o yaml | kubectl apply -f - || true
        fi

    - name: Deploy services
      run: |
        # Create namespace
        kubectl create namespace mcp-system

        # Deploy each service using the Helm charts
        for service in auth-service context-service; do
          if [ -d "gitops/charts/${service}" ]; then
            helm install ${service} gitops/charts/${service} \
              --namespace mcp-system \
              --set image.repository=${{ env.REGISTRY }}/${{ github.repository }}/${service} \
              --set image.tag=${{ github.sha }} \
              --set image.pullPolicy=Never \
              --wait
          fi
        done

        # Deploy text-summarization service
        if [ -d "services/text-summarization/helm/text-summarization" ]; then
          helm install text-summarization services/text-summarization/helm/text-summarization \
            --namespace mcp-system \
            --set image.repository=${{ env.REGISTRY }}/${{ github.repository }}/text-summarization \
            --set image.tag=${{ github.sha }} \
            --set image.pullPolicy=Never \
            --wait
        fi

    - name: Run Alembic migrations
      run: |
        echo "Running Alembic migrations in kind cluster..."
        echo "Waiting for PostgreSQL to be ready..."
        kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=postgresql --timeout=300s || true
        
        # Run main migrations if they exist
        if [ -d "migrations" ]; then
          echo "Running main database migrations..."
          kubectl run alembic-main-migration --rm -i --restart=Never \
            --image=python:3.11-slim \
            --env="DATABASE_URL=postgresql://test_user:test_password@postgres-postgresql:5432/test_mcp_db" \
            --command -- sh -c \
            "pip install alembic psycopg2-binary sqlalchemy && \
             cd /migrations && \
             alembic upgrade head" \
            --overrides='{ "spec": { "containers": [{ "name": "alembic-main-migration", "volumeMounts": [{ "name": "migrations", "mountPath": "/migrations" }] }], "volumes": [{ "name": "migrations", "configMap": { "name": "main-migrations" } }] } }' || true
        fi
        
        # Run context-service migrations if they exist
        if [ -d "services/context-service/migrations" ]; then
          echo "Running context-service migrations..."
          kubectl run alembic-context-migration --rm -i --restart=Never \
            --image=python:3.11-slim \
            --env="DATABASE_URL=postgresql://test_user:test_password@postgres-postgresql:5432/test_mcp_db" \
            --command -- sh -c \
            "pip install alembic psycopg2-binary sqlalchemy && \
             cd /migrations && \
             alembic upgrade head" \
            --overrides='{ "spec": { "containers": [{ "name": "alembic-context-migration", "volumeMounts": [{ "name": "migrations", "mountPath": "/migrations" }] }], "volumes": [{ "name": "migrations", "configMap": { "name": "context-migrations" } }] } }' || true
        fi
        
        echo "Alembic migrations completed!"

    - name: Wait for deployments
      run: |
        kubectl wait --for=condition=available --timeout=300s deployment --all -n mcp-system

    - name: Run smoke tests
      run: |
        # Get service endpoints
        kubectl get services -n mcp-system

        # Run health checks
        echo "Running smoke tests..."
        
        # Test each service health endpoint
        for service in auth-service context-service text-summarization; do
          echo "Testing ${service}..."
          kubectl exec -n mcp-system deployment/${service} -- curl -f http://localhost:8000/healthz || \
          kubectl exec -n mcp-system deployment/${service} -- curl -f http://localhost:8001/healthz || \
          kubectl exec -n mcp-system deployment/${service} -- curl -f http://localhost:8443/health || \
          echo "Health check failed for ${service}"
        done

        # Test basic API functionality
        echo "Testing API endpoints..."
        # Add specific API tests here based on your service APIs

    - name: Verify Cosign signatures
      run: |
        # Install cosign in the cluster and verify signatures
        echo "Verifying image signatures..."
        cosign verify \
          --certificate-identity=https://github.com/${{ github.repository }}/.github/workflows/enhanced-ci-cd.yml@refs/heads/main \
          --certificate-oidc-issuer=https://token.actions.githubusercontent.com \
          ${{ env.REGISTRY }}/${{ github.repository }}/text-summarization:${{ github.sha }}

    - name: Collect deployment logs
      if: failure()
      run: |
        echo "Collecting logs for debugging..."
        kubectl logs -n mcp-system -l app.kubernetes.io/name=auth-service --tail=100
        kubectl logs -n mcp-system -l app.kubernetes.io/name=context-service --tail=100
        kubectl logs -n mcp-system -l app.kubernetes.io/name=text-summarization --tail=100
        
        kubectl describe pods -n mcp-system
        kubectl get events -n mcp-system --sort-by=.metadata.creationTimestamp

    - name: Cleanup
      if: always()
      run: |
        helm uninstall postgres || true
        helm uninstall auth-service -n mcp-system || true
        helm uninstall context-service -n mcp-system || true
        helm uninstall text-summarization -n mcp-system || true
        kubectl delete namespace mcp-system || true

  # Notify and report
  notify:
    name: Notify Results
    runs-on: ubuntu-latest
    needs: [test, integration-test, build, sign, deploy-kind]
    if: always()

    steps:
    - name: Prepare notification
      run: |
        if [[ "${{ contains(needs.*.result, 'failure') }}" == "true" ]]; then
          echo "PIPELINE_STATUS=failed" >> $GITHUB_ENV
          echo "PIPELINE_COLOR=danger" >> $GITHUB_ENV
        elif [[ "${{ contains(needs.*.result, 'cancelled') }}" == "true" ]]; then
          echo "PIPELINE_STATUS=cancelled" >> $GITHUB_ENV
          echo "PIPELINE_COLOR=warning" >> $GITHUB_ENV
        else
          echo "PIPELINE_STATUS=success" >> $GITHUB_ENV
          echo "PIPELINE_COLOR=good" >> $GITHUB_ENV
        fi

    - name: Report pipeline status
      run: |
        echo "Pipeline Status: ${{ env.PIPELINE_STATUS }}"
        echo "Commit: ${{ github.sha }}"
        echo "Branch: ${{ github.ref_name }}"
        echo "Actor: ${{ github.actor }}"
        
        # In a real scenario, you might send this to Slack, Teams, or another notification system
        # Example:
        # curl -X POST -H 'Content-type: application/json' \
        #   --data '{"text":"Pipeline ${{ env.PIPELINE_STATUS }} for ${{ github.repository }}"}' \
        #   ${{ secrets.SLACK_WEBHOOK_URL }}
